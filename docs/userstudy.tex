%!TEX root=writeup.tex
\section{Proposed User Study}
\label{sec:userstudy}

Our key research question is:
%
\begin{quote}
    Can the tool described thus far improve the speed with which programmers
    accomplish tasks with the command line?
\end{quote}
%
To answer this question we plan to conduct a small pilot user study. Programmers
will be asked to accomplish various tasks at the command line. They will be
divided into two groups: one group will be allowed to use our tool, and the
other will be allowed to use the internet. Both groups will be allowed the use
of manpages and will be allowed to experiment by running their commands.

We hypothesize that our tool will improve the speed with which programmers
devise solutions without impeding the correctness of those solutions.

\paragraph{Task} The programmers will each be asked to perform a small number of
tasks using the command line. The tasks are shown in \autoref{fig:tasks} and
will be drawn from our collected data. Importantly, these tasks will be set
aside before training the tool; they will not be examples the tool has seen
before.

There are several confounding factors to account for: some tasks may be easier
than others, some participants may be more experienced than others, and the
tasks may become easier for the participants as they progres. To control for
these, the tasks have been randomly split into two blocks $T_1$ and $T_2$.
Each participant will each block under one of two setups:
\begin{itemize}
    \item $S_1$ --- access to local manpages and the internet
    \item $S_2$ --- access to local manpages and our tool
\end{itemize}

There are four possible combinations of (block, setup) assignments and
orderings; participants will be randomly assigned to one of these four groups:
\begin{itemize}
    \item $T_1 S_1$, $T_2 S_2$ --- task 1 under setup 1 followed by task 2 under setup 2
    \item $T_1 S_2$, $T_2 S_1$ --- task 1 under setup 2 followed by task 2 under setup 1
    \item $T_2 S_1$, $T_1 S_2$ --- task 2 under setup 1 followed by task 1 under setup 2
    \item $T_2 S_2$, $T_1 S_1$ --- task 2 under setup 2 followed by task 1 under setup 1
\end{itemize}

While the tasks all have one-line solutions, those solutions may involve exotic
commands or flags. The programmers will be allowed to produce multi-line scripts
as solutions, provided that those scripts correctly automate the task. We will
not impose any specific time limit on the participants.

\begin{figure}[ht]
    \begin{subfigure}[b]{0.48\textwidth}
        \begin{framed}
        \begin{itemize}\itemsep-1pt
            \item In the current directory, recursively find all files with ``conf''
                in the filename
            \item Recursively remove all empty sub-directories from a directory tree
            \item Find files that are not executable
            \item Find the 100 biggest files on your system
            \item Make a tar archive of a folder, excluding .png files
        \end{itemize}
        \end{framed}
        \caption{Task set $T_1$}
    \end{subfigure}
    \begin{subfigure}[b]{0.48\textwidth}
        \begin{framed}
        \begin{itemize}\itemsep-1pt
            \item ...
            \item ...
            \item ...
            \item ...
            \item ...
        \end{itemize}
        \end{framed}
        \caption{Task set $T_2$}
    \end{subfigure}
    \caption{Tasks for the user study, randomly divided into two groups.}
    \vspace{-10pt}
    \label{fig:tasks}
\end{figure}

\paragraph{Participants} The participants in the study will be undergraduate and
graduate students. They will be proficient command-line users, but not
necessarily experts. We expect to perform the study with at least five
participants in each group.

\paragraph{Measurements} We will primarily measure two things:
\begin{enumerate}\itemsep-1pt
    \item How long do participants take to perform each task?
    \item Are the participants' solutions correct?
\end{enumerate}
We will measure the participants' speed by having them specifically indicate
when they have completed each task. We will measure correctness by having them
save the output from each task; we will compare that output against the correct
solution. \autoref{tbl:user-study-results} shows a placeholder table for what
numbers we would be interested in reporting.

\begin{table}
    \begin{center}
    \begin{tabular}{lrr}
        \textbf{Task/Setup} & \textbf{Without (s)} & \textbf{With (s)} \\
        \hline
        $T_1 S_1$, $T_2 S_2$ & - & - \\
        $T_1 S_2$, $T_2 S_1$ & - & - \\
        $T_2 S_1$, $T_1 S_2$ & - & - \\
        $T_2 S_2$, $T_1 S_1$ & - & - \\
    \end{tabular}
    \end{center}
    \caption{User study results. The ``Task/Setup'' column shows that tasks
        would be performed under what setups and in what order. The ``Without (s)''
        column shows the average time taken by participants on the task with
        setup 1 (manpages+internet). The ``With (s)'' column shows the average
        time taken by participants on the task with setup 2 (manpages+tool).}
    \label{tbl:user-study-results}
\end{table}

\paragraph{Internal Measures} Additionally, we plan to quantify several internal
measures about the tool:
\begin{enumerate}\itemsep-1pt
    \item Performance: how long does training take to produce a model? How
        long does the tool take to answer a query?
    \item For a large number of hand-picked inputs, how often does the
        tool produce a correct answer?
    \item How often is the output close to correct, requiring only small
        adjustment? (``Small adjustment'' is defined as removing flags or
        changing arguments. Adding an argument, changing a command, or
        adding a pipe operator are not small adjustments.)
\end{enumerate}
